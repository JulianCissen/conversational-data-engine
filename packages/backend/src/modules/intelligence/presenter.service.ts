import { Injectable } from '@nestjs/common';
import {
  FieldDefinition,
  ServiceBlueprint,
} from '../blueprint/interfaces/blueprint.interface';
import { LlmMessage } from '../../core/llm/llm.types';
import { PromptExecutionService } from './prompt-execution.service';
import { PROMPT_KEYS } from '../../core/prompt/prompt.constants';
import { SystemMessageBuilder } from './system-message.builder';
import { PromptService } from '../../core/prompt/prompt.service';
import { TemplateService } from '../../core/template/template.service';

@Injectable()
export class PresenterService {
  constructor(
    private readonly promptExecutionService: PromptExecutionService,
    private readonly promptService: PromptService,
    private readonly templateService: TemplateService,
  ) {}

  /**
   * Generate a question to ask the user for a specific field for the first time.
   * @param field The field definition containing the question template and context
   * @param languageConfig Optional language configuration for strict enforcement
   * @param history Optional conversation history to include
   * @returns A natural language question generated by the AI
   */
  public async generateQuestion(
    field: FieldDefinition,
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    const baseSystemPrompt = this.promptService.getPrompt(
      PROMPT_KEYS.PRESENTER_QUESTION,
    );

    const builder = new SystemMessageBuilder(
      baseSystemPrompt,
      this.promptService,
      this.templateService,
    )
      .withContext({
        questionTemplate: field.questionTemplate,
        aiContext: field.aiContext,
      })
      .withLanguageConfig(languageConfig);

    // For initial question generation, there's no actual user message yet
    // We use an empty string as the user message
    return await this.promptExecutionService.executeChat(builder, history, '');
  }

  /**
   * Generate an error response when user input fails local validation.
   * Explains the error gently and re-asks the question.
   * @param field The field definition that failed validation
   * @param invalidInput The user's invalid input
   * @param errorReason The reason why the input was invalid
   * @param languageConfig Optional language configuration for strict enforcement
   * @param history Optional conversation history to include
   * @returns A natural language error message and re-prompt
   */
  public async generateErrorResponse(
    field: FieldDefinition,
    invalidInput: string,
    errorReason: string = 'The provided value is missing or does not match the expected format.',
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    const baseSystemPrompt = this.promptService.getPrompt(
      PROMPT_KEYS.PRESENTER_ERROR,
    );

    const builder = new SystemMessageBuilder(
      baseSystemPrompt,
      this.promptService,
      this.templateService,
    )
      .withContext({
        questionTemplate: field.questionTemplate,
        invalidInput: invalidInput,
        errorReason: errorReason,
      })
      .withLanguageConfig(languageConfig);

    return await this.promptExecutionService.executeChat(builder, history, '');
  }

  /**
   * Generate a contextual response when the user asks a question instead of answering.
   * Answers their question using the blueprint context, then steers back to the form.
   * @param field The current field definition
   * @param userQuestion The user's question about the form
   * @param languageConfig Optional language configuration for strict enforcement
   * @param history Optional conversation history to include
   * @returns A contextual answer followed by a re-prompt
   */
  public async generateContextualResponse(
    field: FieldDefinition,
    userQuestion: string,
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    const baseSystemPrompt = this.promptService.getPrompt(
      PROMPT_KEYS.PRESENTER_CONTEXTUAL,
    );

    const builder = new SystemMessageBuilder(
      baseSystemPrompt,
      this.promptService,
      this.templateService,
    )
      .withContext({
        questionTemplate: field.questionTemplate,
        aiContext: field.aiContext,
        userQuestion: userQuestion,
      })
      .withLanguageConfig(languageConfig);

    // Use the user's actual question as the user message
    return await this.promptExecutionService.executeChat(
      builder,
      history,
      userQuestion,
    );
  }

  /**
   * Get the welcome message for new conversations.
   * @returns The welcome message string
   */
  public getWelcomeMessage(): string {
    return 'Hello! What service would you like to use today?';
  }

  /**
   * Format a list of available services for display.
   * @param services Array of service blueprints
   * @returns Formatted service list with prompt
   */
  public formatServiceList(services: ServiceBlueprint[]): string {
    const serviceList = services.map((s) => `â€¢ ${s.name} (${s.id})`).join('\n');

    return `Here are the available services:\n\n${serviceList}\n\nWhich service would you like to use?`;
  }

  /**
   * Get the error message when service selection is unclear.
   * @returns The unclear selection error message
   */
  public getServiceSelectionUnclearResponse(): string {
    return 'I\'m not sure which service you\'re looking for. Could you please clarify? You can also ask "What services are available?" to see all options.';
  }

  /**
   * Get the completion message when all data has been collected.
   * @returns The completion message string
   */
  public getCompletionMessage(): string {
    return 'Thank you! I have collected all the necessary information. Your request has been completed.';
  }

  /**
   * Get the fallback message when next step cannot be determined.
   * @returns The fallback message string
   */
  public getFallbackMessage(): string {
    return "I'm not sure what to ask next.";
  }

  /**
   * Generate a language requirement announcement for strict language mode.
   * @param languageCode The ISO language code (e.g., 'nl-NL', 'de-DE')
   * @param history Optional conversation history to include
   * @returns A message announcing the language requirement in the target language
   */
  public async getLanguageRequirementAnnouncement(
    languageCode: string,
    history: LlmMessage[] = [],
  ): Promise<string> {
    const baseSystemPrompt = this.promptService.getPrompt(
      PROMPT_KEYS.PRESENTER_LANGUAGE_ANNOUNCEMENT,
    );

    const builder = new SystemMessageBuilder(
      baseSystemPrompt,
      this.promptService,
      this.templateService,
    ).withContext({
      languageCode: languageCode,
    });

    return await this.promptExecutionService.executeChat(builder, history, '');
  }
}
