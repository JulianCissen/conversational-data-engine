import { Injectable } from '@nestjs/common';
import {
  FieldDefinition,
  ServiceBlueprint,
} from '../blueprint/interfaces/blueprint.interface';
import { LlmMessage } from '../../core/llm/llm.types';
import { PromptExecutionService } from './prompt-execution.service';
import { PROMPT_KEYS } from '../../core/prompt/prompt.constants';
import { SystemMessageBuilder } from './system-message.builder';
import { PromptService } from '../../core/prompt/prompt.service';

@Injectable()
export class PresenterService {
  constructor(
    private readonly promptExecutionService: PromptExecutionService,
    private readonly promptService: PromptService,
  ) {}

  /**
   * Generate a question to ask the user for a specific field for the first time.
   * @param field The field definition containing the question template and context
   * @param languageConfig Optional language configuration for strict enforcement
   * @param history Conversation history for context
   * @returns A natural language question generated by the AI
   */
  public async generateQuestion(
    field: FieldDefinition,
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    return this.generateResponse(
      PROMPT_KEYS.PRESENTER_QUESTION,
      {
        questionTemplate: field.questionTemplate,
        aiContext: field.aiContext,
      },
      languageConfig,
      history,
    );
  }

  /**
   * Generate an error response when user input fails local validation.
   * Explains the error gently and re-asks the question.
   * The user's invalid input is expected to be the last message in the history.
   * @param field The field definition that failed validation
   * @param errorReason The reason why the input was invalid
   * @param languageConfig Optional language configuration for strict enforcement
   * @param history Conversation history including the invalid user message
   * @returns A natural language error message and re-prompt
   */
  public async generateErrorResponse(
    field: FieldDefinition,
    errorReason: string = 'The provided value is missing or does not match the expected format.',
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    // Extract the invalid input from the last user message in history
    const invalidInput =
      history.length > 0 && history[history.length - 1].role === 'user'
        ? history[history.length - 1].content
        : '[unknown input]';

    return this.generateResponse(
      PROMPT_KEYS.PRESENTER_ERROR,
      {
        questionTemplate: field.questionTemplate,
        invalidInput: invalidInput,
        errorReason: errorReason,
      },
      languageConfig,
      history,
    );
  }

  /**
   * Generate a contextual response when the user asks a question instead of answering.
   * Answers their question using the blueprint context, then steers back to the form.
   * The user's question is expected to be the last message in the history.
   * @param field The current field definition
   * @param languageConfig Optional language configuration for strict enforcement
   * @param history Conversation history including the user's question
   * @returns A contextual answer followed by a re-prompt
   */
  public async generateContextualResponse(
    field: FieldDefinition,
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    return this.generateResponse(
      PROMPT_KEYS.PRESENTER_CONTEXTUAL,
      {
        questionTemplate: field.questionTemplate,
        aiContext: field.aiContext,
      },
      languageConfig,
      history,
    );
  }

  /**
   * Generic method to generate a response using a specific prompt and context.
   * @param promptKey The prompt key to retrieve from the prompt service
   * @param context The context variables to pass to the template
   * @param languageConfig Optional language configuration for strict enforcement
   * @param history Conversation history for context
   * @returns A natural language response generated by the AI
   */
  private async generateResponse(
    promptKey: string,
    context: Record<string, any>,
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    const baseSystemPrompt = this.promptService.getPrompt(promptKey);

    const builder = new SystemMessageBuilder(baseSystemPrompt)
      .withContext(context)
      .withLanguageConfig(languageConfig);

    return await this.promptExecutionService.executeChat(builder, history);
  }

  /**
   * Generate a welcome message for new conversations.
   * @param services Array of service blueprints to display
   * @param languageConfig Optional language configuration for localization
   * @param history Conversation history for context
   * @returns A natural language welcome message generated by the AI
   */
  public async generateWelcomeMessage(
    services: ServiceBlueprint[],
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    const serviceList = services.map((s) => `• ${s.name} (${s.id})`).join('\n');

    return this.generateResponse(
      PROMPT_KEYS.PRESENTER_WELCOME,
      {
        serviceList: serviceList,
      },
      languageConfig,
      history,
    );
  }

  /**
   * Generate a formatted list of available services for display.
   * @param services Array of service blueprints
   * @param languageConfig Optional language configuration for localization
   * @param history Conversation history for context
   * @returns A natural language service list generated by the AI
   */
  public async generateServiceList(
    services: ServiceBlueprint[],
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    const serviceList = services.map((s) => `• ${s.name} (${s.id})`).join('\n');

    return this.generateResponse(
      PROMPT_KEYS.PRESENTER_SERVICE_LIST,
      {
        serviceList: serviceList,
      },
      languageConfig,
      history,
    );
  }

  /**
   * Generate a response when service selection is unclear.
   * @param languageConfig Optional language configuration for localization
   * @param history Conversation history including the unclear user message
   * @returns A natural language unclear selection message generated by the AI
   */
  public async generateUnclearSelectionResponse(
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    return this.generateResponse(
      PROMPT_KEYS.PRESENTER_UNCLEAR_SELECTION,
      {},
      languageConfig,
      history,
    );
  }

  /**
   * Generate a completion message when all data has been collected.
   * @param serviceName The name of the service that was completed
   * @param languageConfig Optional language configuration for localization
   * @param history Conversation history for context
   * @returns A natural language completion message generated by the AI
   */
  public async generateCompletionMessage(
    serviceName: string,
    languageConfig?: { mode: 'adaptive' | 'strict'; defaultLanguage: string },
    history: LlmMessage[] = [],
  ): Promise<string> {
    return this.generateResponse(
      PROMPT_KEYS.PRESENTER_COMPLETION,
      {
        serviceName: serviceName,
      },
      languageConfig,
      history,
    );
  }

  /**
   * Get the fallback message when next step cannot be determined.
   * This indicates a system error and should not occur in normal operation.
   * @returns The fallback error message string
   */
  public getFallbackMessage(): string {
    return 'I apologize, but something unexpected happened. Please try again or contact support if the issue persists.';
  }

  /**
   * Generate a language requirement announcement for strict language mode.
   * @param languageCode The ISO language code (e.g., 'nl-NL', 'de-DE')
   * @param history Conversation history for context
   * @returns A message announcing the language requirement in the target language
   */
  public async getLanguageRequirementAnnouncement(
    languageCode: string,
    history: LlmMessage[] = [],
  ): Promise<string> {
    return this.generateResponse(
      PROMPT_KEYS.PRESENTER_LANGUAGE_ANNOUNCEMENT,
      {
        languageCode: languageCode,
      },
      undefined,
      history,
    );
  }
}
