# ==========================================
# LLM Configuration
# ==========================================
# API key for the LLM service
LLM_API_KEY=your-api-key-here

# Base URL for the LLM API endpoint
LLM_BASE_URL=https://api.openai.com/v1

# Model name to use for LLM requests
LLM_MODEL=gpt-4

# Temperature for LLM responses (0-2, default: 0)
# Higher values make output more random, lower values more deterministic
LLM_TEMPERATURE=0

# ==========================================
# Plugin Configuration
# ==========================================
# Absolute path to directory where plugins are located (default: <backend>/plugins)
PLUGINS_DIRECTORY=/absolute/path/to/plugins

# ==========================================
# Server Configuration
# ==========================================
# Port for the backend server (default: 3001)
# PORT=3001
